{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Purchased: integer (nullable = true)\n",
      "\n",
      "+---+-------+------+---------+\n",
      "|Age| Income|Gender|Purchased|\n",
      "+---+-------+------+---------+\n",
      "| 25|50000.0|  Male|        1|\n",
      "| 45|64000.0|Female|        0|\n",
      "| 35|57000.0|Female|        1|\n",
      "| 50|   NULL|  Male|        0|\n",
      "| 23|52000.0|  NULL|        1|\n",
      "| 31|60000.0|Female|        0|\n",
      "| 38|58000.0|  Male|        1|\n",
      "+---+-------+------+---------+\n",
      "\n",
      "+-------+------------------+------------------+------+------------------+\n",
      "|summary|               Age|            Income|Gender|         Purchased|\n",
      "+-------+------------------+------------------+------+------------------+\n",
      "|  count|                 7|                 6|     6|                 7|\n",
      "|   mean|35.285714285714285|56833.333333333336|  NULL|0.5714285714285714|\n",
      "| stddev|  9.94508732514511| 5154.286242213044|  NULL|0.5345224838248488|\n",
      "|    min|                23|           50000.0|Female|                 0|\n",
      "|    max|                50|           64000.0|  Male|                 1|\n",
      "+-------+------------------+------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"PredictiveModel\").getOrCreate()\n",
    "\n",
    "# Define the schema for the dataset\n",
    "schema = StructType([\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Income\", DoubleType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Purchased\", IntegerType(), True)  # 1 for 'Yes', 0 for 'No'\n",
    "])\n",
    "\n",
    "# Hardcoded data\n",
    "data = [\n",
    "    (25, 50000.0, \"Male\", 1),\n",
    "    (45, 64000.0, \"Female\", 0),\n",
    "    (35, 57000.0, \"Female\", 1),\n",
    "    (50, None, \"Male\", 0),      # Missing income value\n",
    "    (23, 52000.0, None, 1),     # Missing gender value\n",
    "    (31, 60000.0, \"Female\", 0),\n",
    "    (38, 58000.0, \"Male\", 1)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Display the schema and the dataset\n",
    "df.printSchema()\n",
    "df.show()\n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+---------+------------------+--------------+--------------+\n",
      "|Age| Income| Gender|Purchased|    Income_imputed|Gender_indexed|Gender_encoded|\n",
      "+---+-------+-------+---------+------------------+--------------+--------------+\n",
      "| 25|50000.0|   Male|        1|           50000.0|           1.0| (2,[1],[1.0])|\n",
      "| 45|64000.0| Female|        0|           64000.0|           0.0| (2,[0],[1.0])|\n",
      "| 35|57000.0| Female|        1|           57000.0|           0.0| (2,[0],[1.0])|\n",
      "| 50|   NULL|   Male|        0|56833.333333333336|           1.0| (2,[1],[1.0])|\n",
      "| 23|52000.0|Unknown|        1|           52000.0|           2.0|     (2,[],[])|\n",
      "| 31|60000.0| Female|        0|           60000.0|           0.0| (2,[0],[1.0])|\n",
      "| 38|58000.0|   Male|        1|           58000.0|           1.0| (2,[1],[1.0])|\n",
      "+---+-------+-------+---------+------------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill missing categorical values for \"Gender\" column\n",
    "df = df.fillna({\"Gender\": \"Unknown\"})\n",
    "\n",
    "# Step 1: Impute missing values for \"Income\"\n",
    "imputer = Imputer(inputCols=[\"Income\"], outputCols=[\"Income_imputed\"])\n",
    "\n",
    "# Step 2: Index the \"Gender\" column\n",
    "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"Gender_indexed\")\n",
    "\n",
    "# Step 3: One-Hot Encode the indexed \"Gender\" column\n",
    "gender_encoder = OneHotEncoder(inputCol=\"Gender_indexed\", outputCol=\"Gender_encoded\")\n",
    "\n",
    "# Create a pipeline for the transformations\n",
    "pipeline = Pipeline(stages=[imputer, gender_indexer, gender_encoder])\n",
    "\n",
    "# Fit the pipeline and transform the data\n",
    "try:\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "    df_transformed.show()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 19:27:02 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 4 (= number of training instances)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Assemble features into a single vector\n",
    "assembler = VectorAssembler(inputCols=[\"Age\", \"Income_imputed\", \"Gender_encoded\"], outputCol=\"features\")\n",
    "data = assembler.transform(df_transformed)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"Purchased\", featuresCol=\"features\")\n",
    "model = dt.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Initialize evaluators for different metrics\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Purchased\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Purchased\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Purchased\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "# Display metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
