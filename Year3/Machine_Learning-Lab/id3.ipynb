{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "{'Outlook': {'Sunny': {'Temperature': {'Hot': 'No', 'Mild': 'Yes', 'Cool': 'Yes'}}, 'Overcast': 'Yes', 'Rainy': {'Humidity': {'High': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}, 'Low': 'No'}}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate the Entropy of a dataset\n",
    "def entropy(data):\n",
    "    # Count the occurrences of each class in the target column\n",
    "    class_counts = data.iloc[:, -1].value_counts()\n",
    "    probabilities = class_counts / len(data)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "# Calculate Information Gain of a feature\n",
    "def information_gain(data, feature):\n",
    "    # Calculate the total entropy of the dataset\n",
    "    total_entropy = entropy(data)\n",
    "    \n",
    "    # Group the data by the feature and calculate the weighted average of the entropy of each subset\n",
    "    feature_values = data[feature].value_counts()\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    for value, count in feature_values.items():\n",
    "        subset = data[data[feature] == value]\n",
    "        weighted_entropy += (count / len(data)) * entropy(subset)\n",
    "    \n",
    "    # Information Gain is the reduction in entropy\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# ID3 Algorithm to create a Decision Tree\n",
    "def id3(data, features):\n",
    "    # If all rows have the same class, return a leaf node\n",
    "    if len(data.iloc[:, -1].unique()) == 1:\n",
    "        return data.iloc[0, -1]\n",
    "    \n",
    "    # If no features left to split on, return the majority class\n",
    "    if len(features) == 0:\n",
    "        return data.iloc[:, -1].mode()[0]\n",
    "    \n",
    "    # Find the feature with the highest Information Gain\n",
    "    gains = {feature: information_gain(data, feature) for feature in features}\n",
    "    best_feature = max(gains, key=gains.get)\n",
    "    \n",
    "    # Create the tree\n",
    "    tree = {best_feature: {}}\n",
    "    \n",
    "    # Remove the best feature from the list of features\n",
    "    remaining_features = [feature for feature in features if feature != best_feature]\n",
    "    \n",
    "    # Split the data on the best feature and recursively build the tree\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        tree[best_feature][value] = id3(subset, remaining_features)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Example dataset (replace with your own data)\n",
    "data = pd.DataFrame({\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Rainy', 'Overcast', 'Sunny', 'Sunny', 'Rainy'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Mild', 'Mild', 'Cool', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'High', 'Low', 'Low', 'Low', 'Low', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "# List of features (excluding the target column)\n",
    "features = data.columns[:-1].tolist()\n",
    "\n",
    "# Build the Decision Tree using ID3\n",
    "tree = id3(data, features)\n",
    "print(\"Decision Tree:\")\n",
    "print(tree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
